{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#from torch.nn import Module, Linear\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "#from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10e6949e8>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e638f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "f = plt.figure(figsize=(16,10))\n",
    "M = 100\n",
    "a_list = [random.uniform(1,3) for i in range(M)]\n",
    "b_list = [random.uniform(2,5) for i in range(M)]   \n",
    "\n",
    "ax3 = f.add_subplot(111)\n",
    "ax3.plot(a_list,np.zeros(len(a_list)),marker='o',color='r')\n",
    "ax3.plot(b_list,np.zeros(len(b_list)),marker='o',color='g')\n",
    "ax3.plot([0,5],[0,0],color='b',linestyle='--') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.72910016 1.73591742 1.65734361 2.48079694 2.47167498 2.01496202\n",
      " 2.32512823 2.31018494 1.88829409 1.2890372  1.98729752 1.12981424\n",
      " 2.94843503 2.90650337 1.36069667 1.03336569 2.96286805 1.52274813\n",
      " 2.79714888 2.38480028 1.75469588 1.17645896 2.72816086 2.08193456\n",
      " 1.09838609 1.76861878 1.76339646 1.96740585 1.0117214  2.89042155\n",
      " 1.30869161 1.04516688 2.51956842 1.04122881 2.17183523 2.48733998\n",
      " 1.78004975 1.10990144 1.2147433  1.08662319 2.2691172  1.04656395\n",
      " 2.73666837 1.22829488 1.18203183 1.71642486 2.54906664 2.18581165\n",
      " 2.00551924 2.58437549 1.85869558 1.43757029 2.82801499 2.21392594\n",
      " 1.11501161 1.08449934 1.23925886 2.36239423 2.34539258 2.00635798\n",
      " 2.75908201 1.13484883 2.68627776 1.96645818 1.85644987 2.24216361\n",
      " 1.36395367 2.4538378  1.02959648 1.35785997 2.97173843 1.2068391\n",
      " 2.34882994 1.39060481 1.42537942 1.96698742 2.23987351 1.02343657\n",
      " 1.15853582 1.45767565 1.75850447 2.77790526 2.26563367 2.08788339\n",
      " 1.99763231 2.47989662 1.09757408 2.97146947 1.31209196 1.92439401\n",
      " 1.61322916 1.06413987 2.0875011  2.24268656 1.2599106  2.18621268\n",
      " 1.96197933 1.84310865 2.09947099 1.35775407]\n",
      "[3.04624643 4.55723166 2.11562635 2.25890319 2.8499526  2.44604808\n",
      " 4.83836483 3.01930023 3.16691345 4.79456187 2.3865832  2.92801286\n",
      " 4.66471741 2.65753269 2.2857573  4.90114979 2.69298733 2.19989401\n",
      " 2.56363422 4.03133179 2.63607287 4.99178137 2.47849509 3.62110965\n",
      " 4.75686832 2.56373001 4.4431121  4.82640475 3.29367497 2.18404616\n",
      " 3.4638175  4.19699882 2.14370012 3.56493987 4.81021798 4.63660909\n",
      " 3.33557141 4.75534587 2.73786102 2.9674864  4.6224355  2.41280526\n",
      " 2.32149227 3.40597514 3.26408848 4.48058757 3.16062573 3.86348636\n",
      " 2.29412871 4.86342092 4.4906794  2.37358536 4.52737848 3.15334885\n",
      " 2.04871448 2.2363368  4.9976752  3.42028173 4.51809528 4.01238804\n",
      " 2.94174468 2.86052289 2.78773439 2.26822767 4.17904704 2.96783744\n",
      " 2.03327516 3.11051178 2.7238107  4.92167095 4.23038508 2.00443497\n",
      " 2.27997539 4.85234242 4.2486558  2.01050089 2.83069206 2.23690009\n",
      " 4.00306646 2.80898431 3.07371308 2.23188654 3.81254024 4.75167506\n",
      " 3.8280821  2.29933638 3.78060437 4.12108102 3.20360326 2.68171652\n",
      " 2.54827994 4.15825714 2.09089044 2.68383703 4.15546674 2.8184912\n",
      " 4.25480072 2.01117092 4.25788169 4.25958656]\n"
     ]
    }
   ],
   "source": [
    "a_dataset = np.array(a_list)\n",
    "print (a_dataset.flatten())\n",
    "b_dataset = np.array(b_list)\n",
    "print (b_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mlp, self).__init__()\n",
    "        self.fc1 = nn.Linear(1,1000)\n",
    "        self.fc2 = nn.Linear(1000,2)\n",
    "    def foward(self,x):\n",
    "        x = F.relu(self.fc1(a))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61312604]\n",
      "tensor([[ 0.6131]])\n",
      "tensor([[ 0.6131]])\n"
     ]
    }
   ],
   "source": [
    "real = a_dataset.flatten()\n",
    "fake = b_dataset.flatten()\n",
    "samples = np.concatenate((real, fake))\n",
    "\n",
    "left, right = samples.min(), samples.max()\n",
    "#print (samples.min())\n",
    "#print (samples.max())\n",
    "margin = (right - left) / 10\n",
    "#print (margin)\n",
    "#print (left - margin)\n",
    "#print (right + margin)\n",
    "left -= margin\n",
    "right += margin\n",
    "#print (left)\n",
    "\n",
    "#print (right)\n",
    "\n",
    "test_pts = np.linspace(left, right, 1).astype('float32')\n",
    "test_pts_t = torch.from_numpy(test_pts.reshape(-1, 1))\n",
    "print (test_pts)\n",
    "print (test_pts_t)\n",
    "print (Variable(test_pts_t))\n",
    "#print (test_pts)\n",
    "model = Mlp()\n",
    "#print (test_pts.shape)\n",
    "#scores = model(Variable(test_pts_t)).data.cpu().numpy().flatten()\n",
    "\n",
    "#scores = model(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "\n",
    "model = Mlp()\n",
    "if is_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "bs = len(real)\n",
    "print (bs)\n",
    "ones_label  = torch.ones(bs, 1)\n",
    "#print (ones_label)\n",
    "zeros_label = torch.zeros(bs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def weights_init_msra(m):\n",
    "    \"\"\"\n",
    "    Modified version of msra init\n",
    "    \"\"\"\n",
    "#    classname = m.__class__.__name__\n",
    "#    if classname.find('Linear') != -1:\n",
    "#        m.weight.data.normal_(0.0, np.sqrt(2.0 / m.in_features))\n",
    "#        m.bias.data.fill_(0.02)\n",
    "#    elif classname.find('BatchNorm') != -1:\n",
    "#        m.weight.data.normal_(1.0, 0.02)\n",
    "#        m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    m.weight.data.normal_(0.0, np.sqrt(2.0 / m.in_features))\n",
    "    m.bias.data.fill_(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(net, real_dataset, fake_dataset):\n",
    "    real = real_dataset.flatten()\n",
    "    fake = fake_dataset.flatten()\n",
    "    samples = np.concatenate((real, fake))\n",
    "    bs = len(real)\n",
    "    ones_label  = torch.ones(bs, 1)\n",
    "    zeros_label = torch.zeros(bs, 1)\n",
    "    \n",
    "    #net.apply(weights_init)\n",
    "    optimizer   = optim.Adam(net.parameter(), lr=0.01, betas=(0.5, 0.9))\n",
    "    prob_D_real, prob_D_fake = 0., 0.\n",
    "    \n",
    "    left, right = samples.min(), samples.max()\n",
    "    margin = (right - left) / 10\n",
    "    left -= margin\n",
    "    right += margin\n",
    "\n",
    "    test_pts = np.linspace(left, right, 1000).astype('float32')\n",
    "    test_pts_gpu = torch.from_numpy(test_pts.reshape(-1, 1)).cuda()\n",
    "    \n",
    "    for it in range(1, 10001):\n",
    "        net.zero_grad()\n",
    "        x_real = Variable(torch.from_numpy(real.astype('float32')))\n",
    "        x_fake = Variable(torch.from_numpy(fake.astype('float32')))\n",
    "        \n",
    "        loss_real = loss(net(x_real), Variable(ones_label))\n",
    "        loss_fake = loss(net(x_fake), Variable(zeros_label))\n",
    "        \n",
    "        loss_real.backward()\n",
    "        loss_fake.backward()\n",
    "        \n",
    "        prob_real += np.exp(-loss_real.data[0])\n",
    "        prob_fake += 1 - np.exp(-loss_fake.data[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        if it % 100 == 0 or it == 1:\n",
    "            prob_real /= 100\n",
    "            prob_fake /= 100\n",
    "            fig_w, fig_h, dpi = 800, 600, 100\n",
    "            titlestr = f'iter {it}/{iteration}, probability for real: {prob_D_real:.7}, fake: {prob_D_fake:.7}'\n",
    "            print(titlestr)\n",
    "            fig = plt.figure(figsize=(fig_w/dpi, fig_h/dpi), dpi=dpi)\n",
    "            ax  = fig.add_subplot(111)\n",
    "            \n",
    "            real_sample = real.flatten()\n",
    "            fake_sample = fake.flatten()\n",
    "\n",
    "            scores = net(Variable(test_pts_gpu)).data.cpu().numpy()\n",
    "\n",
    "            ax.scatter(real_sample, np.zeros(real_sample.shape), c='red', marker='+', s=100, label='real')\n",
    "            ax.scatter(fake_sample, np.zeros(fake_sample.shape), c='blue', marker='x', s=100, label='fake')\n",
    "            ax.plot(test_pts, scores)\n",
    "            plt.ylim([-0.1, 1.1])\n",
    "            plt.xlim([left, right])\n",
    "\n",
    "            plt.xticks(fontsize=12)\n",
    "            plt.yticks(fontsize=12)\n",
    "            plt.title(titlestr, fontsize=12)\n",
    "            plt.legend(loc=2, fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{workdir}/{it:06}.png')\n",
    "\n",
    "            plt.close('all')\n",
    "\n",
    "            prob_D_real = 0.\n",
    "            prob_D_fake = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator():\n",
    "    return Mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    netD = get_discriminator()\n",
    "    print(netD)\n",
    "\n",
    "    train_discriminator(netD, a_dataset, b_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(D, real_dataset, fake_dataset, iteration=10000, draw_iter=100, lr=0.0001):\n",
    "\n",
    "    real_sample = real_dataset.flatten()\n",
    "    fake_sample = fake_dataset.flatten()\n",
    "    samples = np.concatenate((real_sample, fake_sample))\n",
    "\n",
    "    left, right = samples.min(), samples.max()\n",
    "    margin = (right - left) / 10\n",
    "    left -= margin\n",
    "    right += margin\n",
    "\n",
    "    test_pts = np.linspace(left, right, 1000).astype('float32')\n",
    "    test_pts_gpu = torch.from_numpy(test_pts.reshape(-1, 1)).cuda()\n",
    "\n",
    "    bs = real_dataset.shape\n",
    "    D.apply(weights_init_msra)\n",
    "    D = D.cuda()\n",
    "\n",
    "    optimizer   = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.9))\n",
    "    ones_label  = torch.ones(bs, 1).cuda()\n",
    "    zeros_label = torch.zeros(bs, 1).cuda()\n",
    "    loss        = nn.BCELoss()\n",
    "\n",
    "    prob_D_real, prob_D_fake = 0., 0.\n",
    "    for it in range(1, iteration + 1):\n",
    "        D.zero_grad()\n",
    "        # Sample data\n",
    "        x_fake = Variable(torch.from_numpy(fake_dataset.batch_next().astype('float32'))).cuda()\n",
    "        x_real = Variable(torch.from_numpy(real_dataset.batch_next().astype('float32'))).cuda()\n",
    "\n",
    "        loss_fake = loss(D(x_fake), Variable(zeros_label))\n",
    "        loss_real = loss(D(x_real), Variable(ones_label))\n",
    "\n",
    "        loss_fake.backward()\n",
    "        loss_real.backward()\n",
    "\n",
    "        prob_D_real += np.exp(-loss_real.data[0])\n",
    "        prob_D_fake += 1 - np.exp(-loss_fake.data[0])\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if it % draw_iter == 0 or it == 1:\n",
    "            prob_D_real /= draw_iter\n",
    "            prob_D_fake /= draw_iter\n",
    "\n",
    "            fig_w, fig_h, dpi = 800, 600, 100\n",
    "\n",
    "            titlestr = f'iter {it}/{iteration}, probability for real: {prob_D_real:.7}, fake: {prob_D_fake:.7}'\n",
    "            print(titlestr)\n",
    "\n",
    "            fig = plt.figure(figsize=(fig_w/dpi, fig_h/dpi), dpi=dpi)\n",
    "            ax  = fig.add_subplot(111)\n",
    "\n",
    "            real_sample = real_dataset.batch_next(32).flatten()\n",
    "            fake_sample = fake_dataset.batch_next(32).flatten()\n",
    "\n",
    "            scores = D(Variable(test_pts_gpu)).data.cpu().numpy().flatten()\n",
    "\n",
    "            ax.scatter(real_sample, np.zeros(real_sample.shape), c='red', marker='+', s=100, label='real')\n",
    "            ax.scatter(fake_sample, np.zeros(fake_sample.shape), c='blue', marker='x', s=100, label='fake')\n",
    "            ax.plot(test_pts, scores)\n",
    "            plt.ylim([-0.1, 1.1])\n",
    "            plt.xlim([left, right])\n",
    "\n",
    "            plt.xticks(fontsize=12)\n",
    "            plt.yticks(fontsize=12)\n",
    "            plt.title(titlestr, fontsize=12)\n",
    "            plt.legend(loc=2, fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{workdir}/{it:06}.png')\n",
    "\n",
    "            plt.close('all')\n",
    "\n",
    "            prob_D_real = 0.\n",
    "            prob_D_fake = 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
